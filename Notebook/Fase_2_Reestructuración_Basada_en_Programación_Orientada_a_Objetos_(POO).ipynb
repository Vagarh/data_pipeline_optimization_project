{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "b6EbqRNWXZ4I",
        "outputId": "ddb728ae-6571-4cac-853b-a8e1329831b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_70f328a8-6023-4701-8475-be0ec9124ade\", \"Final_Combined_DataFrame.xlsx\", 3704810)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "class FilmDataProcessor:\n",
        "    def __init__(self, file_path):\n",
        "        # Inicializar con la ruta del archivo Excel\n",
        "        self.file_path = file_path\n",
        "        self.dataframes = {}\n",
        "\n",
        "    def load_data(self):\n",
        "        # Cargar los datos de cada hoja y limpiar los nombres de las columnas\n",
        "        sheet_names = ['film', 'inventory', 'rental', 'customer', 'store']\n",
        "        for sheet in sheet_names:\n",
        "            df = pd.read_excel(self.file_path, sheet_name=sheet)\n",
        "            df.columns = df.columns.str.strip()  # Eliminar espacios en los nombres de las columnas\n",
        "            self.dataframes[sheet] = df\n",
        "\n",
        "    def clean_data(self):\n",
        "        # Limpieza de cada hoja cargada\n",
        "        for sheet_name, df in self.dataframes.items():\n",
        "            if sheet_name == 'film':\n",
        "                df = self.clean_film(df)\n",
        "            elif sheet_name == 'inventory':\n",
        "                df = self.clean_inventory(df)\n",
        "            elif sheet_name == 'rental':\n",
        "                df = self.clean_rental(df)\n",
        "            elif sheet_name == 'customer':\n",
        "                df = self.clean_customer(df)\n",
        "            elif sheet_name == 'store':\n",
        "                df = self.clean_store(df)\n",
        "            # Actualizar el DataFrame limpio en el diccionario\n",
        "            self.dataframes[sheet_name] = df\n",
        "\n",
        "    def clean_film(self, df):\n",
        "        # Limpieza específica de la hoja 'film'\n",
        "        df['film_id'] = pd.to_numeric(df['film_id'].astype(str).str.replace(r'[^0-9]', '', regex=True), errors='coerce').astype('Int64')\n",
        "        df['title'] = df['title'].astype(str).str.strip()\n",
        "        df['release_year'] = pd.to_numeric(df['release_year'].astype(str).str.replace(r'[^0-9]', '', regex=True), errors='coerce').astype('Int64')\n",
        "        df['last_update'] = pd.to_datetime(df['last_update'], errors='coerce')\n",
        "        return df\n",
        "\n",
        "    def clean_inventory(self, df):\n",
        "        # Limpieza específica de la hoja 'inventory'\n",
        "        df['inventory_id'] = pd.to_numeric(df['inventory_id'].astype(str).str.replace(r'[^0-9]', '', regex=True), errors='coerce').astype('Int64')\n",
        "        df['last_update'] = pd.to_datetime(df['last_update'], errors='coerce')\n",
        "        return df\n",
        "\n",
        "    def clean_rental(self, df):\n",
        "        # Limpieza específica de la hoja 'rental'\n",
        "        df['rental_id'] = pd.to_numeric(df['rental_id'].astype(str).str.replace(r'[^0-9]', '', regex=True), errors='coerce').astype('Int64')\n",
        "        df['rental_date'] = pd.to_datetime(df['rental_date'], errors='coerce')\n",
        "        df['return_date'] = pd.to_datetime(df['return_date'], errors='coerce')\n",
        "        df['last_update'] = pd.to_datetime(df['last_update'], errors='coerce')\n",
        "        return df\n",
        "\n",
        "    def clean_customer(self, df):\n",
        "        # Limpieza específica de la hoja 'customer'\n",
        "        df['customer_id'] = pd.to_numeric(df['customer_id'].astype(str).str.replace(r'[^0-9]', '', regex=True), errors='coerce').astype('Int64')\n",
        "        if 'customer_id_old' in df.columns:\n",
        "            df = df.drop(columns=['customer_id_old'])\n",
        "        df['last_update'] = pd.to_datetime(df['last_update'], errors='coerce')\n",
        "        return df\n",
        "\n",
        "    def clean_store(self, df):\n",
        "        # Limpieza específica de la hoja 'store'\n",
        "        df['store_id'] = pd.to_numeric(df['store_id'].astype(str).str.replace(r'[^0-9]', '', regex=True), errors='coerce').astype('Int64')\n",
        "        df['last_update'] = pd.to_datetime(df['last_update'], errors='coerce')\n",
        "        return df\n",
        "\n",
        "    def combine_data(self):\n",
        "        # Unir los DataFrames cargados y limpiados\n",
        "        df_film_inventory = pd.merge(self.dataframes['inventory'], self.dataframes['film'], how='left', on='film_id', suffixes=('_inventory', '_film'))\n",
        "        df_film_inventory_rental = pd.merge(self.dataframes['rental'], df_film_inventory, how='left', on='inventory_id', suffixes=('_rental', '_film_inventory'))\n",
        "        df_film_inventory_rental_customer = pd.merge(df_film_inventory_rental, self.dataframes['customer'], how='left', on='customer_id', suffixes=('_rental', '_customer'))\n",
        "\n",
        "        # Verificar si 'store_id_customer' existe antes de la unión final\n",
        "        if 'store_id_customer' in df_film_inventory_rental_customer.columns and 'store_id' in self.dataframes['store'].columns:\n",
        "            df_final = pd.merge(df_film_inventory_rental_customer, self.dataframes['store'], how='left', left_on='store_id_customer', right_on='store_id', suffixes=('_customer', '_store'))\n",
        "            return df_final\n",
        "        else:\n",
        "            raise KeyError(\"La columna 'store_id_customer' no se encuentra en df_film_inventory_rental_customer o la columna 'store_id' no se encuentra en df_store.\")\n",
        "\n",
        "    def save_and_download(self, df_final, output_file_name):\n",
        "        # Guardar y descargar el archivo Excel combinado\n",
        "        output_file_path = f'/content/{output_file_name}.xlsx'\n",
        "        df_final.to_excel(output_file_path, index=False)\n",
        "        files.download(output_file_path)\n",
        "\n",
        "# Uso de la clase FilmDataProcessor\n",
        "file_path = '/content/Films_2.xlsx'  # Ajustar según la ruta en Google Colab\n",
        "film_processor = FilmDataProcessor(file_path)\n",
        "\n",
        "# Cargar, limpiar, combinar, y guardar los datos\n",
        "film_processor.load_data()\n",
        "film_processor.clean_data()\n",
        "df_final = film_processor.combine_data()\n",
        "film_processor.save_and_download(df_final, 'Final_Combined_DataFrame')\n"
      ]
    }
  ]
}